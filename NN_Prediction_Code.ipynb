{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Prediction_Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chin6wGDkFb8"
      },
      "source": [
        "# ***Importing Necessary Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkkRRUrioEN3"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI6mMcbrkPCD"
      },
      "source": [
        "# **Prediction Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPjk7eq8oOBq"
      },
      "source": [
        "class Prediction:\r\n",
        "\r\n",
        "  def __init__(self, dir_to_data, dir_to_thetas_metadata):\r\n",
        "    \r\n",
        "    #read  input data and remove the example (row) whose values are not provided or contains NA.\r\n",
        "    self.data=pd.read_csv(dir_to_data).dropna()\r\n",
        "    \r\n",
        "    #list for storing thetas of each layer\r\n",
        "    self.thetas=[]\r\n",
        "\r\n",
        "    #read meta data from the file in the same order as it was written to the file\r\n",
        "    with open(dir_to_thetas_metadata, 'rb') as file:\r\n",
        "      \r\n",
        "      #read the total number of layers in the network\r\n",
        "      self.no_of_layers = np.load(file)\r\n",
        "\r\n",
        "      #read and use corresponding activation function\r\n",
        "      activation_fnt = np.load(file, allow_pickle=True)\r\n",
        "      if activation_fnt == 'Sigmoid':\r\n",
        "        self.ActivationFnt = self.SigmoidFnt\r\n",
        "      else:\r\n",
        "        self.ActivationFnt = self.ReLU\r\n",
        "\r\n",
        "      #read thetas\r\n",
        "      for i in range(self.no_of_layers-1):\r\n",
        "        self.thetas.append(np.load(file))\r\n",
        "      \r\n",
        "      #read column names which needs to be removed\r\n",
        "      remove_cols = np.load(file)\r\n",
        "      \r\n",
        "      #remove columns not required in the features\r\n",
        "      if len(remove_cols):\r\n",
        "        self.data=self.data.drop(remove_cols, axis=1)\r\n",
        "\r\n",
        "      #read data related to scaling\r\n",
        "      self.scale=np.load(file)\r\n",
        "      self.scale_type=np.load(file, allow_pickle=True)\r\n",
        "\r\n",
        "      #read minimium and maximum values of the dataset used for creating model\r\n",
        "      self.min=np.load(file, allow_pickle=True)\r\n",
        "      self.max=np.load(file, allow_pickle=True)\r\n",
        "  \r\n",
        "    #if number of columns of the input data (features) is not equal to the nodes in the input layer\r\n",
        "    if self.data.shape[1] != self.thetas[0].shape[0] -1:\r\n",
        "      sys.exit(f'Features provided are either more or less than input nodes. Please check your input data file.') \r\n",
        "\r\n",
        "\r\n",
        "  #Perform scaling of the features\r\n",
        "  def scaleDataset(self):\r\n",
        "\r\n",
        "    if self.scale_type: #between 0 and 1\r\n",
        "      self.data = self.data.apply(lambda x: (x-self.min)/(self.max-self.min), axis=1)\r\n",
        "    \r\n",
        "    else: #between -1 and 1\r\n",
        "      self.data = self.data.apply(lambda x: 2*((x-self.min)/(self.max-self.min))-1, axis=1)\r\n",
        "\r\n",
        "\r\n",
        "  #Add bias to the activations as column vector\r\n",
        "  def AddBias(self, X):\r\n",
        "    return np.c_[ np.ones(X.shape[0]), X]\r\n",
        "\r\n",
        "  #Apply linear function\r\n",
        "  def LinearFnt(self, X, theta):\r\n",
        "    return np.dot(X, theta)\r\n",
        "\r\n",
        "  #Apply Sigmoid function\r\n",
        "  def SigmoidFnt(self, Z):\r\n",
        "    return 1/(1+(np.exp(-Z)))\r\n",
        "\r\n",
        "  #Apply ReLU\r\n",
        "  def ReLU(self, Z):\r\n",
        "    return np.maximum(0, Z)\r\n",
        "\r\n",
        "  #perform prediction on input data\r\n",
        "  def prediction(self):\r\n",
        "    \r\n",
        "    #scale the dataset\r\n",
        "    if self.scale:\r\n",
        "      self.scaleDataset()\r\n",
        "    \r\n",
        "    self.data =self.data.to_numpy()\r\n",
        "\r\n",
        "    #Forward Propagation\r\n",
        "    for i in range(self.no_of_layers):\r\n",
        "\r\n",
        "      if i == 0: #input layer\r\n",
        "        activations=self.AddBias(self.data)\r\n",
        "\r\n",
        "      elif i == self.no_of_layers -1: #output layer\r\n",
        "        output=self.LinearFnt(activations, self.thetas[i-1]) #no activation function\r\n",
        "\r\n",
        "      else:\r\n",
        "        activations =self.AddBias(self.ActivationFnt(self.LinearFnt(activations, self.thetas[i-1])))\r\n",
        "\r\n",
        "    print(f'The Predicted Values for the given inputs is: \\n{output}')\r\n",
        "    return output\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B0gs3VWa74T"
      },
      "source": [
        "# **Output**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN2BcIqNgMD-"
      },
      "source": [
        "# *Worldwide*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqDY1_F5o95a"
      },
      "source": [
        "#directories to the data\r\n",
        "dir_to_data_world ='/content/World_Data_Template_For_Prediction_Code.csv'\r\n",
        "dir_to_thetas_metadata_world='/content/Optimal_thetas_of Neural_Network_with_Metadata_Worldwide.npy'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNYFyNYEbBIt",
        "outputId": "425f3ab3-b854-4ffa-93a5-4b8b0ee86dfc"
      },
      "source": [
        "pred_world=Prediction(dir_to_data_world, dir_to_thetas_metadata_world)\r\n",
        "_=pred_world.prediction()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Predicted Values for the given inputs is: \n",
            "[[191208.13486694]\n",
            " [191208.13486694]\n",
            " [191208.13486694]\n",
            " [191208.13486694]\n",
            " [191208.13486694]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW6Gn4KegZ23"
      },
      "source": [
        "## *US*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhMjvBalgcs8"
      },
      "source": [
        "#directories to the data\r\n",
        "dir_to_data_US ='/content/US_Data_Template_For_Prediction_Code.csv'\r\n",
        "dir_to_thetas_metadata_US='/content/Optimal_thetas_of Neural_Network_with_Metadata_US.npy'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuohkDDmgehd",
        "outputId": "3479d408-ac4e-47e4-da06-f93f9d31cb3a"
      },
      "source": [
        "pred_US=Prediction(dir_to_data_US, dir_to_thetas_metadata_US)\r\n",
        "_=pred_US.prediction()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Predicted Values for the given inputs is: \n",
            "[[23009.74989366]\n",
            " [23009.74989392]\n",
            " [23009.74989364]\n",
            " [23009.7498939 ]\n",
            " [23009.74989383]\n",
            " [23009.74989384]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}